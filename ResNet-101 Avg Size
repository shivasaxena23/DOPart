import torch
import torch.nn as nn
import torchvision.models as models
import torchvision.transforms as transforms
import torchvision.datasets as datasets
import time
from collections import defaultdict

# ===== Config =====
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
NUM_RUNS = 5

# ===== Load CIFAR Sample & Resize =====
transform = transforms.Compose([
    transforms.Resize(224),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225])
])

dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)
x, _ = dataset[0]
x = x.unsqueeze(0).to(device)  # Add batch dimension

# ===== Load ResNet-101 =====
model = models.resnet101(pretrained=True)
model.fc = nn.Linear(model.fc.in_features, 10)
model = model.to(device)
model.eval()

# ===== Timing Structures =====
timing_data = defaultdict(list)
input_sizes = {}

# ===== Hooks =====
def pre_hook(name):
    def hook(module, input):
        torch.cuda.synchronize() if torch.cuda.is_available() else None
        tensor = input[0]
        size_bytes = tensor.element_size() * tensor.nelement()
        input_sizes[name] = size_bytes
        timing_data[name].append({'start': time.time()})
    return hook

def post_hook(name):
    def hook(module, input, output):
        torch.cuda.synchronize() if torch.cuda.is_available() else None
        timing_data[name][-1]['end'] = time.time()
    return hook

# ===== Attach Hooks to Leaf Layers =====
handles = []
for name, module in model.named_modules():
    if len(list(module.children())) == 0:
        handles.append(module.register_forward_pre_hook(pre_hook(name)))
        handles.append(module.register_forward_hook(post_hook(name)))

# ===== Run Forward Passes =====
with torch.no_grad():
    for _ in range(NUM_RUNS):
        _ = model(x)

# ===== Remove Hooks =====
for h in handles:
    h.remove()

# ===== Process Data =====
average_times = []
input_byte_sizes = []

for name in sorted(timing_data.keys()):
    times = [
        (entry['end'] - entry['start']) * 1000
        for entry in timing_data[name]
    ]
    avg_time = sum(times) / len(times)
    average_times.append(avg_time)
    input_byte_sizes.append(input_sizes.get(name, 0))

# ===== Save to Files =====
with open("layer_runtimes.txt", "w") as f1:
    for t in average_times:
        f1.write(f"{t:.6f}\n")

with open("layer_input_sizes.txt", "w") as f2:
    for s in input_byte_sizes:
        f2.write(f"{s}\n")

print("\n✅ Data saved to:")
print("  → layer_runtimes.txt (ms)")
print("  → layer_input_sizes.txt (bytes)")
